{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pre_trained.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCcSPU-XwBBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "50faa9f8-c096-4292-8b3f-b6c1279e48a5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ockTfrpwE2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/content/drive/My Drive/Img'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Covjo7kZwQOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "31b74db0-2985-47e6-92e7-bbb6a80d1132"
      },
      "source": [
        "#first we import needed libiraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os \n",
        "import glob2 as gb\n",
        "import cv2\n",
        "import scipy.optimize as opt\n",
        "import sys\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "np.random.seed(2)\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')\n",
        "\n",
        "#code characters    \n",
        "code = {'0':0, '1':1, '2':2, '3':3, '4':4,\n",
        "               '5':5, '6':6, '7':7, '8':8, '9':9,\n",
        "               'A':10, 'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16,\n",
        "               'H':17, 'I':18, 'J':19, 'K':20, 'L':21, 'M':22, 'N':23,\n",
        "               'O':24, 'P':25, 'Q':26, 'R':27, 'S':28, 'T':29, 'U':30,\n",
        "               'V':31, 'W':32, 'X':33, 'Y':34, 'Z':35, 'As':36, 'Bs':37, \n",
        "               'Cs':38, 'Ds':39, 'Es':40, 'Fs':41, 'Gs':42, 'Hs':43, 'Is':44, \n",
        "               'Js':45, 'Ks':46, 'Ls':47, 'Ms':48, 'Ns':49, 'Os':50, 'Ps':51,\n",
        "               'Qs':52, 'Rs':53, 'Ss':54, 'Ts':55, 'Us':56, 'Vs':57, 'Ws':58, \n",
        "               'Xs':59, 'Ys':60, 'Zs':61,}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khi8oBV7w_rI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8cfa3ac-6bbb-4733-b047-e6c9558b5a0f"
      },
      "source": [
        "#read dataset from specific file in your device\n",
        "train_path = '/content/drive/My Drive/Img/'\n",
        "dataset_path = train_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#create X and Y\n",
        "x=[]\n",
        "y=[]\n",
        "\n",
        "#upload data and resize it\n",
        "for folder in os.listdir(dataset_path):\n",
        "    files = gb.glob(pathname=str(dataset_path)+folder+'/*png')\n",
        "    print(f'for dataset , found {len(files)} in folder {folder}')\n",
        "    for file in files :\n",
        "        image = cv2.imread(file)\n",
        "        image_array = cv2.resize(image,(224,224))\n",
        "        x.append(list(image_array))\n",
        "        y.append(code[folder])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for dataset , found 55 in folder 1\n",
            "for dataset , found 55 in folder 2\n",
            "for dataset , found 55 in folder 9\n",
            "for dataset , found 55 in folder 7\n",
            "for dataset , found 55 in folder 8\n",
            "for dataset , found 55 in folder 3\n",
            "for dataset , found 55 in folder 6\n",
            "for dataset , found 55 in folder 4\n",
            "for dataset , found 55 in folder 5\n",
            "for dataset , found 55 in folder 0\n",
            "for dataset , found 55 in folder A\n",
            "for dataset , found 55 in folder Es\n",
            "for dataset , found 55 in folder As\n",
            "for dataset , found 55 in folder Cs\n",
            "for dataset , found 55 in folder Bs\n",
            "for dataset , found 55 in folder E\n",
            "for dataset , found 55 in folder C\n",
            "for dataset , found 55 in folder B\n",
            "for dataset , found 55 in folder D\n",
            "for dataset , found 55 in folder Ds\n",
            "for dataset , found 55 in folder H\n",
            "for dataset , found 55 in folder F\n",
            "for dataset , found 55 in folder Hs\n",
            "for dataset , found 55 in folder G\n",
            "for dataset , found 55 in folder I\n",
            "for dataset , found 55 in folder Js\n",
            "for dataset , found 55 in folder Gs\n",
            "for dataset , found 55 in folder Is\n",
            "for dataset , found 55 in folder Fs\n",
            "for dataset , found 55 in folder J\n",
            "for dataset , found 55 in folder M\n",
            "for dataset , found 55 in folder Ns\n",
            "for dataset , found 55 in folder O\n",
            "for dataset , found 55 in folder Os\n",
            "for dataset , found 55 in folder K\n",
            "for dataset , found 55 in folder Ks\n",
            "for dataset , found 55 in folder L\n",
            "for dataset , found 55 in folder Ls\n",
            "for dataset , found 55 in folder Ms\n",
            "for dataset , found 55 in folder N\n",
            "for dataset , found 55 in folder T\n",
            "for dataset , found 55 in folder Rs\n",
            "for dataset , found 55 in folder P\n",
            "for dataset , found 55 in folder Ps\n",
            "for dataset , found 55 in folder R\n",
            "for dataset , found 55 in folder Ts\n",
            "for dataset , found 55 in folder Q\n",
            "for dataset , found 55 in folder Qs\n",
            "for dataset , found 55 in folder Ss\n",
            "for dataset , found 55 in folder S\n",
            "for dataset , found 55 in folder Us\n",
            "for dataset , found 55 in folder Vs\n",
            "for dataset , found 55 in folder Y\n",
            "for dataset , found 55 in folder Ys\n",
            "for dataset , found 55 in folder Xs\n",
            "for dataset , found 55 in folder W\n",
            "for dataset , found 55 in folder V\n",
            "for dataset , found 55 in folder U\n",
            "for dataset , found 55 in folder Ws\n",
            "for dataset , found 55 in folder X\n",
            "for dataset , found 55 in folder Z\n",
            "for dataset , found 55 in folder Zs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLjX709yxttH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "16978248-5893-4a24-b518-654be49d4dc7"
      },
      "source": [
        "plt.imshow (x [55])\n",
        "print (y [55])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD+CAYAAADYg6v8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAbVklEQVR4nO3de1BU5/0/8PcuslxUbiqK4CUlQlDSGGHG2FStEIttvGSqFgRJ1VHbmUgzdTSFaCD1mkVr0BmMZhptJjLQscQLSMA21pjRUTEOjuhEjQKKrIDcBBGUs8/3D3/sL+TAsuztLMv7NeMfe855zvNZjrw55+zZ51EJIQSIiH5ErXQBROR4GAxEJMNgICIZBgMRyTAYiEiGwUBEMjYNhrKyMsTGxiImJgaxsbEoLy+3ZXdEZCU2DYa0tDTEx8ejqKgI8fHxSE1NtWV3RGQlKls94FRXV4eYmBhcuHABLi4ukCQJU6dOxcmTJ+Hn52e0bVtbG0pLSzFixAi4uLjYojyiAU2SJNTW1iI8PBzu7u6y9YNs1bFOp8PIkSMNv9guLi7w9/eHTqfrNRhKS0uRkJBgq9KI6P/JyspCZGSkbLnNgsESI0aMAPC86FGjRilcDZHzefDgARISEgy/az9ls2AICAhAdXU1JEkyXErU1NQgICCg17adZxmjRo1CUFCQrUokGvB6ulS32c3HYcOGISwsDPn5+QCA/Px8hIWF9XoZQUTKs+mlxIcffojk5GTs3bsXXl5e0Gq1tuyOiKzEpsEQHByMw4cP27ILIrIBPvlIRDIMBiKSYTAQkQyDgYhkGAxEJMNgICIZBgMRyTAYiEiGwUBEMgwGIpJhMBCRDIOBiGQYDEQkw2AgIhkGAxHJWDQeQ0NDA9577z3cvXsXGo0G48aNw6ZNm+Dn54fQ0FCEhIRArX6ePenp6QgNDbVK0URkWxYFg0qlwsqVKzF16lQAgFarxc6dO7Ft2zYAQE5ODgYPHmx5lURkVxZdSvj4+BhCAQAmT56Mqqoqi4siImVZbWg3vV6P7OxsREVFGZYlJiZCkiTMmDEDSUlJ0Gg01uqOiGzIajcfN2/eDE9PTyxduhQAcPr0aXz55ZfIysrCDz/8gMzMTGt1RUQ2ZpVg0Gq1qKioQEZGhuFmY+f8EUOGDMHixYtx+fJla3RFRHZgcTDs2rULpaWlyMzMNFwqNDU1oa2tDQDQ0dGBoqIihIWFWdoVEdmJRfcYbt26hf3792P8+PGIi4sDAAQFBWHlypVITU2FSqVCR0cHXn31Vbz77rtWKZiIbM+iYJgwYQJu3LjR7bq8vDxLdk1ECuKTj0Qkw2AgIhkGAxHJMBiISIbBQEQyDAYikmEwEJEMg4GIZBgMRCTDYCAiGQYDEckwGIhIhsFARDIMBiKSYTAQkQyDgYhkLB4lOioqChqNBm5ubgCAdevWYfr06SgpKUFqaira29sRGBiIHTt2YNiwYRYXTES2Z5Xh4/fs2YOQkBDDa71ej/Xr12P79u2IjIzE3r17sXPnTmzfvt0a3RGRjdnkUqK0tBRubm6IjIwEAMTFxaGwsNAWXRGRDVjljGHdunUQQiAiIgJr166FTqfD6NGjDev9/Pyg1+vR2NgIHx8fa3RJRDZk8RlDVlYWjh8/jtzcXAghsGnTJmvURUQKsjgYOieW0Wg0iI+Px+XLlxEQENBlDsv6+nqo1WqeLRD1ExYFQ2trK5qbmwEAQggUFBQgLCwM4eHhaGtrw6VLlwA8n/V6zpw5lldLRHZh0T2Guro6JCUlQZIk6PV6BAcHIy0tDWq1Gunp6UhLS+vycSUR9Q8WBcOYMWNw9OjRbtdNmTKFk84Q9VN88pGIZBgMRCTDYCAiGQYDEclY5clH6t+++eYbaDQaPHz4EFVVVfjNb36DsWPHKl0WKYjBMIDcvHkTGRkZKCkp6bK8rq4OarUa7e3taG9vx759++Dh4dFlmxkzZiAlJQXe3t72LJkUwmBwUk1NTcjIyOjycfKTJ09QWVmJx48fG23746dWO12/fh0FBQWYPXs2tmzZIgsOci4MBifS2tqKdevW4fTp05AkCTU1NWhsbLTKvpuamnD16lWUl5ejo6MD6enphjE4yPkwGJxEa2srJk2ahJqaGrS2ttqsn+bmZnz22WfYunUrg8GJ8VMJJ9De3o4XX3wR5eXlNg2FTo8fP0ZISAja2tps3hcpg2cM/VxHRwcCAwNRV1dn1351Oh2EEHbtk+yHZwz9mF6vx/Tp0+0eCp1GjRqFZ8+eKdI32RaDoZ+7cOGCYn0/evQIiYmJ0Ov1itVAtsFg6KeEEBg8eLDip/OHDx9WvAayPgZDP+YIN//0ej3GjRvHcHAyFt18rKysxDvvvGN43dzcjJaWFly8eLHH+SbIckIIrF69WukyDO7fv690CWRlFgVDUFAQjh07Zni9detWSJJkeP3T+SbIev7xj38oXUIXEyZMwK1bt6BSqZQuhazAapcST58+RV5eHhYuXGitXVIPlLzh2JPbt28rXQJZkdWeYzh16hRGjhyJSZMmGZb9dL4JLy8va3U3oP3iF79QugRyclY7Y8jNze1ytsD5JgYePtPgPKwSDNXV1SguLsa8efMMy7qbb4Ici6urKzw9PeHp6YnBgwd3+efi4tLn/cXExNigSlKCVYLhyJEjmDlzJnx9fQH0PN8EKcvNzQ3e3t7w8fGBj48PkpOTUVtbi9raWrS0tBj+NTU14de//nWfbySePXvWRpWTvVnlHsORI0ewYcMGw+ue5psg+xs0aBB8fX3h7e2NJUuWIDk5GZ6enkbbuLi4YPHixbh69SoqKytN7qujo8PScslBWCUYioqKurw2Nt8E2dfLL7+MixcvYtCgvh3q5cuX45///GefgoGcB598dHKurq59DoVOYWFhGDx4cJ/a3Llzx6y+yLEwGPqhiRMnmrTd0KFD8frrr5vdz759+/DSSy+ZvL0QAqGhoWb3R46DwdAPXb16tddtXF1dMXPmTOzatcsOFf1//M6Ec2Aw9FO//OUvja4fPXo09u7da6dqyNkwGPohlUqFM2fOYNasWbL7B66uroiOjkZ0dDTGjBmjUIXU33Fot35KpVLhv//9L5YsWdJlOHgfHx8cOnTIav28/PLLuH79Op48eWJym7a2Nri7u1utBrI/BkM/plar8a9//cumfaxevRr/+9//UFFRYXKb1tZWBkM/x0sJMurMmTOGp1hN5efnZ6NqyF4YDGTU4cOHUV9fr3QZZGcMBiKSYTBQjw4cONDtPJbGREdH26gasicGA/XowIED0Ol0Jm+vUqk47oaTYDBQt1paWsz6tuTUqVNtUA3ZG4OBurV7926O4ziAMRioW6dPn8bDhw/71GbGjBk2qobsrddg0Gq1iIqKQmhoKG7evGlYXlZWhtjYWMTExCA2Nhbl5eUmrSPHt3XrVly5cqXP7T7++GMbVENK6DUYoqOjkZWVhcDAwC7L09LSEB8fj6KiIsTHxyM1NdWkdeT4Ll68iNra2j63mzx5sg2qISX0GgyRkZGGgV071dXV4fr165g7dy4AYO7cubh+/Trq6+uNriPndfDgQaVLICsy67sSOp0OI0eONIwk7OLiAn9/f+h0OgghelzHR2Ud3/vvv49vvvmmz+1+//vfcxYqJ8Kbj9RFWVkZmpqa+tzOw8PDBtWQUsw6YwgICEB1dTUkSYKLiwskSUJNTQ0CAgIghOhxHTm25ORk5Ofn97nd3//+dxtUQ0oy64xh2LBhCAsLM/wnys/PR1hYGPz8/IyuI8dWU1ODlpaWPrdbtWqVDaohJfV6xrBlyxacPHkSDx8+xPLly+Hj44MTJ07gww8/RHJyMvbu3QsvLy9otVpDG2PryDGlpKQgOzu7z+3c3d3h6enJ+wtOptdg2LhxIzZu3ChbHhwcjMOHD3fbxtg6ckzNzc1oa2vrc7u7d+9CreatKmfDI0r44IMP8Omnn5rV1tvbm2cLTohDuw1wW7duxfbt2yFJUp/bzp8/n2cLTopHdQB79uwZnjx5YlYoAEBWVpZZs2KT42MwDGC7d+/Gtm3bzGobHh4OV1dXXkY4KV5KDEBCCGRmZmL9+vVm7+PcuXPQaDRWrIocCc8YBqCDBw8iKSnJ7PYeHh5QqVQ8W3BiDIYBRq/XQ6/Xm91epVLh/v37GDJkiBWrIkfDYBhA9Ho9cnJyLHpSMS4ujpcQAwCDYYDQ6/U4duwYEhISzN6HRqPBxx9/jMGDB1uxMnJEDIYB4urVq2Z/AtHpwIED8PHxsVJF5Mj4qcQA8OzZM9y+fRuXLl0yex++vr741a9+BTc3t163FULIxot0cXHhF+n6EQaDExBCoLGxEcDziW69vb0N6549e4aCggIsXLjQ7P27u7ujuLhYNrxfT7VUVFTghRde6LI8KCgI3333Hfz9/c2ug+yHwdBPdf4CCiHQ0dGBv/71rwCAIUOG4G9/+5thu2vXruGtt96yqK8lS5Z0CRtjNd2+fRsTJkyQrausrMS0adNw5swZkwKGlMVg6GcePHiAxsZGCCEQHh7e7UePX3zxhdX6GzduHJKTkzF8+HCj2wkhcPfu3W5DodOdO3cwe/ZsnDp1CqNGjbJajWR9vPnYTzx9+hRXrlzBn//8Z4SFhWHixIkWPY9giuDgYBQUFCAkJMSk7WNjY3vdpry8HCkpKZaWRjbGM4Z+oKKiAiUlJVi0aJFZ08aZw9vbGwcPHsRLL71k0vbFxcW4cOFCr9s9efIE33//vaXlkY2ZFAxarRZFRUW4f/8+8vLyEBISgoaGBrz33nu4e/cuNBoNxo0bh02bNhnuPIeGhiIkJMTwtdz09HSEhoba7p04qbNnz2LPnj3Izc01+1uQ5li0aBFeeOEFk79WPWvWLJP33dzcjGvXrmHSpEnmlke2JkxQXFwsqqqqxKxZs8SNGzeEEEI0NDSI8+fPG7b56KOPREpKiuF1SEiIaGlpMWX3Mvfu3RMhISHi3r17ZrV3Fl9//bXw8vISAOz6b8qUKeK7774zuc6CgoI+7d/V1VUsXLjQhj856k1vv2Mm/TnobtIZHx+fLjMbT548GVVVVSbGEfWmsLAQixYtwqNHj+zab0REBPbu3YspU6aY3KZzciFyHla5x6DX65GdnY2oqKguyxMTEyFJEmbMmIGkpCQ+Y2+i48ePY+XKlWhoaLBrv8OHD8f777+PyMhIk9tkZWVBCGHDqkgJVvlUYvPmzfD09MTSpUsNy06fPo0vv/wSWVlZ+OGHH5CZmWmNrpyeJElITk42a+5ISw0dOhRDhgzp06hMy5Yt63MwjBgxArNnz+5reWRHFgeDVqtFRUUFMjIyutyo6rz0GDJkCBYvXozLly9b2tWAkJWVhbq6OkX6Lisrw6FDh3D79m2Ttj916pRZZwtjx47FH//4xz63I/ux6FJi165dKC0txaefftrlMqGpqQlubm5wd3dHR0cHioqKEBYWZnGxzu7zzz9HSkoKampqFKvhiy++gF6vx7Jly/Daa68ZHXfhgw8+sPmzFKQMk4Khu0lnMjIysH//fowfPx5xcXEAnj8Pn5mZiTt37iA1NRUqlQodHR149dVX8e6779r0jfR32dnZSE1NhU6nU7oUZGVl4datW5g2bRoCAwOxfPnyLk8+fvLJJ7h//z4uXrzY5zOGUaNG8WyhH1AJB7xzVFlZiejoaHz99dcICgpSuhy7ePPNN1FYWOhwf4GHDh2K3/3ud12+bp2Tk4Pq6uo+78vNzQ1vvfUWcnJyrFkimaG33zE++egg2traHC4UgOcPI33++edW2Ze/vz/+8pe/WGVfZFv8roQD2LlzJ65du6Z0GTbn5eXV5dkXclwMBgdw+vRps07N+xN/f3/s3r1b6TLIRAwGhW3btg0XL15Uugyb8/T0RHR0tNJlkIkYDAorKSlR5GEmImMYDEQkw2AYAF555RWzp7m3huHDh+Orr75SrH/qO35c6eQmTpyI48ePY9iwYdDr9fjTn/5k1/59fX1x/vx5BAcH27VfsgyDwYm9+OKL+M9//oPRo0cDeP5t146ODqxZs8ZuNbi7uzMU+iFeSjipsWPH4ty5c4ZQAJ5/MrBixQrs2bMHrq6uNq9h6NChKCkpsXk/ZH0MBicUEBCAkpISjBgxQrbOw8MDq1evRk5ODn7+85/brAYPDw+Ul5dzHol+isHgRFQqFUJCQnDz5k34+vr2uJ2bmxvmz5+Pc+fOIS0tzepnD/7+/qiurubMU/0Yg0Fhv/3tbzF+/HiL9+Pp6YmWlhaUlJSYNEX9oEGDMHjwYGzYsAGffPKJbOYoc6hUKjx+/Bjl5eUYOnSoxfsj5TAYFJaYmIiJEydatA83Nzc0NDTA09MTHh4efWrr6uqKZcuW4fvvv8fbb79tdg1jxoxBW1ubWTWQ42EwKMzFxQVjx46Fp6enWe0nTJiAx48fWzSepouLCzQaDQ4ePIhnz56hvLwc06ZNM6nta6+9hqdPn6KsrIxjejoRk4JBq9UiKioKoaGhuHnzpmF5VFQU5syZgwULFmDBggX49ttvDetKSkowf/58xMTEYMWKFYoNV9Yf7N27F4sWLYK7u7vJbUJDQyFJEm7cuNGnMRqNUavVGDRoEMaOHYuzZ89CkiRIkoSvvvoKTU1Nhtevv/46mpubIUkSzp07h0GDBlmtBnIQpoxB3928EkII2etOkiSJN954QxQXFwshhMjMzBTJyclWG/PeGen1epGQkCA8PDyMzskwadIkIUmS0Ov1dq3tx/3Zs2+yDZvNK2FMaWkp3NzcDMOQx8XFobCwsI+RNbCoVCocOnQIra2tWLhwIdzd3aFWq6FWq/HKK6+gtbUVQgiUlpZCrVZDpVLZtbYf92fPvkkZFj/5uG7dOgghEBERgbVr18LLyws6na7LgzV+fn7Q6/VobGzsMkQYde/f//630iXQAGfRzcesrCwcP34cubm5EEJg06ZN1qqLiBRkUTB0Xl5oNBrEx8cb5o4ICAjoMl1dfX091Go1zxaI+gmzg6G1tRXNzc0AACEECgoKDHNHhIeHo62tDZcuXQLwfFThOXPmWKFcIrIHs+eV2LdvH5KSkiBJEvR6PYKDg5GWlgbg+cde6enpSEtLQ3t7OwIDA7Fjxw6bvhEish7OK0E0APX2O8YnH4lIhsFARDIMBiKSYTAQkQyDgYhkGAxEJMNgICIZBgMRyTAYiEiGwUBEMgwGIpJhMBCRDIOBiGQYDEQkw2AgIhmTBmrRarUoKirC/fv3kZeXh5CQEFRWVuKdd94xbNPc3IyWlhZcvHgRwPM5JzQaDdzc3AA8HzR2+vTpNngLRGRtJgVDdHQ03n77bSQkJBiWBQUF4dixY4bXW7duhSRJXdrt2bMHISEhViqViOzFpGDonB+iJ0+fPkVeXh4+++wzqxRFRMqyeF4JADh16hRGjhyJSZMmdVne3ZwTROT4rHLzMTc3FwsXLuyyjHNOEPVfFgdDdXU1iouLMW/evC7Le5pzgogcn8XBcOTIEcycORO+vr6GZcbmnCAix2f2vBInTpwA8DwYNmzY0GX7urq6HuecICLHx3kliAYgzitBRH3GYCAiGQYDEckwGIhIhsFARDIMBiKSYTAQkQyDgYhkGAxEJMNgICIZBgMRyTAYiEiGwUBEMgwGIpJhMBCRTK/B0NDQgFWrViEmJgbz5s3DmjVrUF9fDwAoKSnB/PnzERMTgxUrVqCurs7Qztg6InJsvQaDSqXCypUrUVRUhLy8PIwZMwY7d+6EXq/H+vXrkZqaiqKiIkRGRmLnzp0AYHQdETm+XoPBx8cHU6dONbyePHkyqqqqUFpaCjc3N8OcE3FxcSgsLAQAo+uIyPH16R6DXq9HdnY2oqKioNPpMHr0aMM6Pz8/6PV6NDY2Gl1HRI6vT8GwefNmeHp6YunSpbaqh4gcgMkzUWm1WlRUVGDfvn1Qq9UICAhAVVWVYX19fT3UajV8fHyMriMix2fSGcOuXbtQWlqKzMxMaDQaAEB4eDja2tpw6dIlAEBOTg7mzJnT6zoicny9njHcunUL+/fvx/jx4xEXFwfg+UzXmZmZSE9PR1paGtrb2xEYGIgdO3YAANRqdY/riMjx9RoMEyZMwI0bN7pdN2XKFOTl5fV5HRE5Nj75SEQyDAYikmEwEJEMg4GIZBgMRCTDYCAiGQYDEckwGIhIhsFARDIMBiKSYTAQkQyDgYhkGAxEJMNgICIZBgMRyTAYiEjG5DEf7UmSJADAgwcPFK6EyDl1/m51/q79lEMGQ21tLQAgISFB4UqInFttbS3GjRsnW64SQggF6jGqra0NpaWlGDFiBFxcXJQuh8jpSJKE2tpahIeHw93dXbbeIYOBiJTFm49EJMNgICIZBgMRyTAYiEiGwUBEMgwGIpJhMBCRDIOBiGQcLhjKysoQGxuLmJgYxMbGory8XOmSTBIVFYU5c+ZgwYIFWLBgAb799lsAQElJCebPn4+YmBisWLECdXV1Clf6nFarRVRUFEJDQ3Hz5k3DcmM/f0c7Nj29h56OBeBYx6OhoQGrVq1CTEwM5s2bhzVr1qC+vr7XOu3yHoSDSUxMFEePHhVCCHH06FGRmJiocEWmmTVrlrhx40aXZZIkiTfeeEMUFxcLIYTIzMwUycnJSpQnU1xcLKqqqmR1G/v5O9qx6ek9dHcshHC849HQ0CDOnz9veP3RRx+JlJQUo3Xa6z04VDA8fPhQREREiI6ODiGEEB0dHSIiIkLU1dUpXFnvuvvPeOXKFfHmm28aXtfV1YnJkyfbuzSjfly3sZ+/Ix8bU4PB0Y9HYWGh+MMf/mC0Tnu9B4f6dqVOp8PIkSMNX5xycXGBv78/dDod/Pz8FK6ud+vWrYMQAhEREVi7di10Oh1Gjx5tWO/n5we9Xo/Gxkb4+PgoWGn3jP38hRD96tj89Fh4eXk59PHQ6/XIzs5GVFSU0Trt9R4c7h5Df5WVlYXjx48jNzcXQghs2rRJ6ZIGrP54LDZv3gxPT08sXbpU6VIAOFgwBAQEoLq62jB4hCRJqKmpQUBAgMKV9a6zRo1Gg/j4eFy+fBkBAQGoqqoybFNfXw+1Wq34X6eeGPv596dj092x6FzuiMdDq9WioqICGRkZUKvVRuu013twqGAYNmwYwsLCkJ+fDwDIz89HWFiYQ56q/lhrayuam5sBAEIIFBQUICwsDOHh4Whra8OlS5cAADk5OZgzZ46SpRpl7OffX45NT8cCgEMej127dqG0tBSZmZnQaDQAjNdpr/fgcOMx3L59G8nJyXj06BG8vLyg1Wrxs5/9TOmyjLp37x6SkpIgSRL0ej2Cg4OxceNG+Pv74/Lly0hLS0N7ezsCAwOxY8cODB8+XOmSsWXLFpw8eRIPHz6Er68vfHx8cOLECaM/f0c7Nt29h3379vV4LAA41PG4desW5s6di/HjxxsGSwkKCkJmZqbROu3xHhwuGIhIeQ51KUFEjoHBQEQyDAYikmEwEJEMg4GIZBgMRCTDYCAimf8D4HnQP+3bSPAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKshivmxyEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "208e7302-9b75-4be6-9466-4e1f2a938ba2"
      },
      "source": [
        "# Split the train and the validation set for the fitting\n",
        "x_train , x_test , y_train , y_test = train_test_split(x, y, test_size = 0.1,random_state = 2 )\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "x_test  = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test  = np.asarray(y_test)\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(x_train[1])\n",
        "print(x_train[0].shape)\n",
        "# print('shape of x_train :', x_train.shape())\n",
        "#print('shape of x_train[5] : ', x_train[5].shape)\n",
        "#print('any image contain : x_train[0] \\n',x_train[0])\n",
        "#print('x_train shape :' , x_train.shape)\n",
        "#print('y_train shape :' , y_train.shape)\n",
        "\n",
        "#print(type(y_train))\n",
        "\n",
        "# next step should be normlize image \n",
        "x_train , x_test = x_train/255.0 , x_test/255.0\n",
        "print('sample x_train[0] : \\n ' ,x_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "sample x_train[0] : \n",
            "  [[[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD+CAYAAADYg6v8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYXElEQVR4nO3de1BU5/0/8PcuZkFAXJcK4TZSb7iBjCBUm2kSFZ1CUjGdOqkUJZ06ONM0wXQsGBwNWEhiF6ilNmt1JnY606E4Y1FuWnDS1ElviRhCMltHqol3VlBgI0IW3D3n+4c/9hc8sOyy5+xF368ZZtxzOM/5nD3um3Pb51GJoiiCiOhr1L4ugIj8D4OBiCQYDEQkwWAgIgkGAxFJMBiISELRYLh06RI2btyIrKwsbNy4EZcvX1ZydUQkE0WDoaysDHl5eWhra0NeXh5KS0uVXB0RyUSl1ANOfX19yMrKwkcffYSgoCDY7XasWLECp06dgk6nc7qs1WqFyWTC3LlzERQUpER5RI80u92OW7duISUlBSEhIZL5M5RasdlsRnR0tOODHRQUhKioKJjN5imDwWQyYdOmTUqVRkT/T21tLTIyMiTTFQsGT8ydOxfA/aIff/xxH1dD9PC5efMmNm3a5PisPUixYIiJiUFPTw/sdrvjVKK3txcxMTFTLjt2lPH4448jPj5eqRKJHnmTnaordvExMjISer0eLS0tAICWlhbo9fopTyOIyPcUPZXYs2cPSkpKcODAAURERMBgMCi5OiKSiaLBsGDBAhw9elTJVRCRAvjkIxFJMBiISILBQEQSDAYikmAwEJEEg4GIJBgMRCTBYCAiCQYDEUkwGIhIgsFARBIMBiKSYDAQkQSDgYgkGAxEJOFRfwwDAwPYsWMHrl69Co1Gg3nz5qG8vBw6nQ5JSUlYvHgx1Or72VNZWYmkpCRZiiYiZXkUDCqVCgUFBVixYgUAwGAwoLq6Gm+//TYA4MiRIwgLC/O8SiLyKo9OJbRarSMUACA1NRXd3d0eF0VEviVb126CIKCurg6ZmZmOafn5+bDb7Xj22WdRWFgIjUYj1+qISEGyXXysqKhAaGgoNm/eDAA4ffo0jh07htraWly8eBFGo1GuVRGRwmQJBoPBgCtXrqCmpsZxsXFs/Ijw8HC8+OKL6OjokGNVROQFHgfDvn37YDKZYDQaHacKX375JaxWKwDAZrOhra0Ner3e01URkZd4dI3hwoULOHToEBITE5GbmwsAiI+PR0FBAUpLS6FSqWCz2ZCWlobXXntNloKJSHkeBcOiRYvQ1dU14bzm5mZPmiYiH+KTj0QkwWAgIgkGAxFJMBiISILBQEQSDAYikmAwEJEEg4GIJBgMRCTBYCAiCQYDEUkwGIhIgsFARBIMBiKSYDAQkQSDgYgkPO4lOjMzExqNBsHBwQCAoqIiPPPMM+js7ERpaSlGRkYQFxeHqqoqREZGelwwESlPlu7j9+/fj8WLFzteC4KA4uJi7N27FxkZGThw4ACqq6uxd+9eOVZHRApT5FTCZDIhODgYGRkZAIDc3Fy0trYqsSoiUoAsRwxFRUUQRRHp6enYvn07zGYzYmNjHfN1Oh0EQYDFYoFWq5VjlUSkII+PGGpra9HU1IT6+nqIoojy8nI56iIiH/I4GMYGltFoNMjLy0NHRwdiYmLGjWHZ398PtVrNowWiAOFRMAwPD2NwcBAAIIoiTp48Cb1ej5SUFFitVpw9exbA/VGvs7OzPa+WiLzCo2sMfX19KCwshN1uhyAIWLBgAcrKyqBWq1FZWYmysrJxtyuJvu6LL75AXV0dRkZGAABPPfUUnnvuOR9XRYCHwZCQkICGhoYJ5y1btoyDztCEBEHA+fPnUVZWhqamJoyOjgK4/3/mzp07eO655xAREeHjKh9tstyVIHKVxWJBfX096uvr8de//nXcvI6ODscR54YNGxwDJJP3MRjIa8xmM7Zt24aPP/4Yly5dmvB3urq68Pbbb2PWrFm8LuVDjGTyit7eXmzZsgV/+ctfJg2FMZ2dnWhqasKNGze8VB09iMFAihoaGsLOnTvxox/9yK2nXxsaGvCf//xHwcrIGZ5KkGKGhobw/PPP47PPPoPFYnFrWbPZjP7+foUqo6nwiIFkJ4oiurq6sHr1anzwwQduhwL5Ho8YSFaCIGDnzp1obGxEV1eXr8uhaWIwkGwEQUBKSgpu3LiBO3fu+Loc8gCDgWQhiiIWLlw45R0HCgwMBpJFQkICby8+RBgM5LHo6Gj09vbK2mZFRQXy8/NlbZNcx7sS5LHbt2/L3mZ4eDhmzpwpe7vkGgYDeUSr1UIQBFnbLCsrwyuvvCJrm+QenkrQtP3iF79w9Mchlx07dmD37t2YMYP/NX2J7z5N2+9//3tZjxa2bduGvXv38luVfsCjYLh+/fq4Q77BwUHcvXsXZ86cmXS8CXo4PPHEE/jqq69kaWvJkiXYs2cPfvjDH0KlUsnSJnnGo2CIj49HY2Oj4/Vbb70Fu93ueP3geBP08Lh27Zos7WRlZeGPf/wjoqOjGQp+RLZTidHRUTQ3N+Pw4cNyNUl+ShAEiKLocTvPP/88WlpaAICh4GdkC4b3338f0dHRSE5Odkx7cLwJdtf1cIiMjMTQ0NC0lw8JCcG6detw9OhRGasiOcl2lae+vh4bNmxwvOZ4Ew+v6f51V6lUSE1NxeXLlxkKfk6WYOjp6UF7eztycnIc0yYab4IC39DQ0LROI8ZC4ZNPPkF0dLQClZGcZAmG48ePY+XKlZgzZw6AyceboMA3f/58t/tXUKlUePLJJ/nHIYDIco3h+PHj2LVrl+P1ZONNUGAbG//BHSqVCsnJyfj0008VqIiUIkswtLW1jXvtbLwJClzHjh1z+9kFnU7nGJGMAgcfMSOXvf76624/Aq1SqRwPuVHgYDCQSz7//HPcu3fPrWXUajUfcAtQDAZyyfr163Hz5k23lgkPD8e//vUvhSoiJTEYyCVj40u6SqVSYf78+QpVQ0pjMNCUPvroIwwPD7u1jEajgcFgUKgiUhqDgaZUUFCA7u5ut5YJCgrCd7/7XYUqIqUxGEh2arUaP/jBD3xdBnmAwUCymzFjBv70pz/5ugzyAIOBnOrt7XX7NmV4eLhC1ZC3MBjIqcOHD7vVNbxKpUJxcbGCFZE3MBjIqfr6egwMDLj8+2q1GiUlJQpWRN7AYCAiCQYDyWr9+vW+LoFkwGAg2ahUKvzyl7/0dRkkAwYDTerXv/41rl696tYyTz75pELVkDdN2R+DwWBAW1sbbty4gebmZse35S5duoSSkhJYLBZotVoYDAYkJiZOOY8Cx+nTp9268AgAnZ2dkk55tFot3nnnHcyaNUvO8khJ4hTa29vF7u5ucfXq1WJXV5djen5+vtjQ0CCKoig2NDSI+fn5Ls1zxbVr18TFixeL165dc2s5ktfKlStFlUolAnD5Z9myZZJpGo1GXLVqlbh27VoxPz9fPHfunK837ZE31WdsylOJjIwMR8euY/r6+nDu3DmsW7cOALBu3TqcO3cO/f39TudRYLHZbG53/DpRv46jo6M4ffo03nvvPRw9ehS5ubnYunWrW89HkHdNq2s3s9mM6OhoBAUFAbj/hZmoqCiYzWaIojjpPJ1OJ1/lFJCsVis+++wzXLx4Eb29vSguLsbTTz/t67LoARzUliZ0/fp1WK1WxdofHh5GW1sb1Go1oqOjsWjRIsXWRe6b1l2JmJgY9PT0OMaptNvt6O3tRUxMjNN5FDhef/11mEwmRdcxMjKC1tZW/O53v1N0PeS+aQVDZGQk9Hq9Y9zBlpYW6PV66HQ6p/MocPT29k6ru3h3Wa1WHD58GDt37lR8XeS6KU8l3nzzTZw6dQq3b9/GT37yE2i1Wpw4cQJ79uxBSUkJDhw4gIiIiHG99TibR/Sg4eFh9Pb2YnR0FBqNxtflEDD17Upf4O1K31u7dq1btyk9/dFoNGJJSYmvN/uR4fHtSiJvGB0dxblz53D+/Hlfl0LgI9HkR1paWvDnP//Z12UQGAzkRwRBgNls5oNPfoDBQBIWi8Xt7tzk8u677+Ldd9/1ybrp/2MwkITFYvHKrcrJiG4+hk3yYzCQBD+YxGAgiZ///Of48MMPfVoDw8m3+F0JklVQUJDjC3RjBEGAzWZzuQ1BECAIgqQd8h4eMZBswsLC8Nvf/hYjIyOOn+HhYXzwwQdutXPv3j23goTkxyMGkkVERAQsFgtUKtW46UFBQZg3b55bbb333nvIzMzEqlWrZKyQ3MEjBpLFRKEwXatWrcLy5ctlaYumh8FAHgsLC5O1vb///e84c+aMrG2SexgM5LGXX3550nmiKOKrr75yq73s7Gz26uRjDAbymLP+PK1WK+rq6rxYDcmBwUAe+8Mf/jDpvLt37+KNN95wq70ZM2ZgxgxeF/clBgMRSbgUyxMNOjMwMIAdO3bg6tWr0Gg0mDdvHsrLyx1duCUlJWHx4sVQq+9nT2VlJZKSkpTbEvI7NpsN//73v91aZtasWYiIiFCoInKVS0cMa9asQW1tLeLi4hzTVCoVCgoK0NbWhubmZiQkJKC6unrcckeOHEFjYyMaGxsZCgFEr9dDq9V63M7Q0BC+//3vu7XM008/zQuPfsClYJho0BmtVosVK1Y4XqempqK7u1ve6sgnfvrTn2LJkiUetWGz2dDU1OT2cmlpaUhLS/No3eQ5Wa7wCIKAuro6ZGZmjpuen58Pu92OZ599FoWFhezoM0Co1WqPHlYSBAHHjx/HSy+9JGNV5E2yXHysqKhAaGgoNm/e7Jh2+vRpHDt2DLW1tbh48SKMRqMcqyIvmD17ttsh3tfX5/i3zWbDtm3b3F5vWFgYB771Ex4Hg8FgwJUrV1BTU+O40AjAceoRHh6OF198ccIxDck/zZ49G4899phby1RWVkIURQiCgP379+PmzZtur/db3/oWvx/hJzwKhn379sFkMsFoNI77C/Pll186hjez2Wxoa2uDXq/3rFLya1VVVQCA3/zmNyguLp5WG0uXLsW3v/1tOcuiaXLpGsNEg87U1NTg0KFDSExMRG5uLgAgPj4eRqMRX3zxBUpLS6FSqWCz2ZCWlobXXntN0Q0h39u1axdqamqmteySJUvw1FNPyVwRTZdLwbB7927s3r1bMr2rq2vC309LS0Nzc7NnlVHA2bt377SXTU9PR1ZWlozVkCf45CNN6OWXX8Y3v/lNr60vLCxMlmcnSB4MBppQTk6O10Yo/853voMtW7Z4ZV3kGgYDTeixxx6TreMVZ2bOnIn09PRxD8uR7zEYaFKzZ89WvEPW5cuX42c/+5mi6yD3MRhoUpWVlVi4cKFi7S9fvhzvvPMOv0fjhxgMNKnk5GSEh4cr1r5Op0NycrJi7dP0MRjIqTfeeGPct2rlkpGRgQMHDnjlOga5j8FATmVlZWH27Nmytrl06VIcO3bMq7dDyT0MBnIqJCQEOTk5sp5ShIeHIyEhQbb2SH4MBprSrl27EBUVJUtbycnJaGxslKUtUg6DgaY0a9YsfPzxxx5fa1i4cCH++c9/IjIyUqbKSCkMBnKJVqvF+fPnpxUOKpUKS5cuxSeffMLHngME++gml4WHh+PChQuIjY2FxWJxaZnIyEhcvXoVarUaISEhCldIcuERA7ll5syZ6OnpcemhpIiICHR3dyM0NJShEGAYDOQ2jUaD//73v7h3796kA8M88cQT6O/vZz+fAWra40oAQGZmJjQaDYKDgwEARUVFeOaZZwAAnZ2dKC0txcjICOLi4lBVVcWLTg+Rse9QjIyMTDhfpVLx4aUANu1xJcbs37/fMXbEWCgIgoDi4mKUlpaira0NGRkZkjEn6OGgVqsn/GEoBLZpjyvhjMlkQnBwMDIyMgAAubm5aG1tnV6FROR1Ht+VKCoqgiiKSE9Px/bt2xEREQGz2YzY2FjH7+h0OgiCAIvFwttVRAHAo4uPtbW1aGpqQn19PURRRHl5uVx1EZEPeRQMY6cXGo0GeXl5jrEjYmJixg1X19/fD7VazaMFogAx7WAYHh7G4OAgAEAURZw8edIxdkRKSgqsVivOnj0L4P7gttnZ2TKUS0TeMO1xJQ4ePIjCwkLY7XYIgoAFCxagrKwMwP0r1ZWVlSgrKxt3u5KIAoNKFEXR10U86Pr161izZg3+9re/IT4+3tflED10pvqM8clHIpJgMBCRBIOBiCQYDEQkwWAgIgkGAxFJMBiISILBQEQSDAYikmAwEJEEg4GIJBgMRCTBYCAiCQYDEUkwGIhIYtrjSly/fh2vvPKK43cGBwdx9+5dnDlzBoDzMSeIyL+5FAxr1qzBSy+9hE2bNjmmxcfHjxvO/K233oLdbh+33P79+x2D0xBR4HApGMbGh5jM6OgompubcfjwYVmKIiLfkmW06/fffx/R0dFITk4eN32iMSeIyP/JcvGxvr4eGzZsGDeNY04QBS6Pg6Gnpwft7e3IyckZN32yMSeIyP95HAzHjx/HypUrMWfOHMc0Z2NOEJH/m/a4EidOnABwPxh27do17vf7+vomHXOCiPwfx5UgegRxXAkichuDgYgkGAxEJMFgICIJBgMRSTAYiEiCwUBEEgwGIpJgMBCRBIOBiCQYDEQkwWAgIgkGAxFJMBiISILBQEQSUwbDwMAAtm7diqysLOTk5ODVV19Ff38/AKCzsxPr169HVlYWtmzZgr6+PsdyzuYRkX+bMhhUKhUKCgrQ1taG5uZmJCQkoLq6GoIgoLi4GKWlpWhra0NGRgaqq6sBwOk8IvJ/UwaDVqvFihUrHK9TU1PR3d0Nk8mE4OBgx5gTubm5aG1tBQCn84jI/7l1jUEQBNTV1SEzMxNmsxmxsbGOeTqdDoIgwGKxOJ1HRP7PrWCoqKhAaGgoNm/erFQ9ROQHXB6JymAw4MqVKzh48CDUajViYmLQ3d3tmN/f3w+1Wg2tVut0HhH5P5eOGPbt2weTyQSj0QiNRgMASElJgdVqxdmzZwEAR44cQXZ29pTziMj/TXnEcOHCBRw6dAiJiYnIzc0FcH+ka6PRiMrKSpSVlWFkZARxcXGoqqoCAKjV6knnEZH/mzIYFi1ahK6urgnnLVu2DM3NzW7PIyL/xicfiUiCwUBEEgwGIpJgMBCRBIOBiCQYDEQkwWAgIgkGAxFJMBiISILBQEQSDAYikmAwEJEEg4GIJBgMRCTBYCAiCQYDEUm43OejN9ntdgDAzZs3fVwJ0cNp7LM19ll7kF8Gw61btwAAmzZt8nElRA+3W7duYd68eZLpKlEURR/U45TVaoXJZMLcuXMRFBTk63KIHjp2ux23bt1CSkoKQkJCJPP9MhiIyLd48ZGIJBgMRCTBYCAiCQYDEUkwGIhIgsFARBIMBiKSYDAQkYTfBcOlS5ewceNGZGVlYePGjbh8+bKvS3JJZmYmsrOz8cILL+CFF17AP/7xDwBAZ2cn1q9fj6ysLGzZsgV9fX0+rvQ+g8GAzMxMJCUl4X//+59jurP339/2zWTbMNm+APxrfwwMDGDr1q3IyspCTk4OXn31VfT3909Zp1e2QfQz+fn5YkNDgyiKotjQ0CDm5+f7uCLXrF69Wuzq6ho3zW63i2vXrhXb29tFURRFo9EolpSU+KI8ifb2drG7u1tSt7P339/2zWTbMNG+EEX/2x8DAwPihx9+6Hj9q1/9Sty5c6fTOr21DX4VDLdv3xbT09NFm80miqIo2mw2MT09Xezr6/NxZVOb6D/jp59+Kn7ve99zvO7r6xNTU1O9XZpTX6/b2fvvz/vG1WDw9/3R2toq/vjHP3Zap7e2wa++XWk2mxEdHe344lRQUBCioqJgNpuh0+l8XN3UioqKIIoi0tPTsX37dpjNZsTGxjrm63Q6CIIAi8UCrVbrw0on5uz9F0UxoPbNg/siIiLCr/eHIAioq6tDZmam0zq9tQ1+d40hUNXW1qKpqQn19fUQRRHl5eW+LumRFYj7oqKiAqGhodi8ebOvSwHgZ8EQExODnp4eR+cRdrsdvb29iImJ8XFlUxurUaPRIC8vDx0dHYiJiUF3d7fjd/r7+6FWq33+12kyzt7/QNo3E+2Lsen+uD8MBgOuXLmCmpoaqNVqp3V6axv8KhgiIyOh1+vR0tICAGhpaYFer/fLQ9WvGx4exuDgIABAFEWcPHkSer0eKSkpsFqtOHv2LADgyJEjyM7O9mWpTjl7/wNl30y2LwD45f7Yt28fTCYTjEYjNBoNAOd1emsb/K4/hs8//xwlJSW4c+cOIiIiYDAYMH/+fF+X5dS1a9dQWFgIu90OQRCwYMEC7N69G1FRUejo6EBZWRlGRkYQFxeHqqoqfOMb3/B1yXjzzTdx6tQp3L59G3PmzIFWq8WJEyecvv/+tm8m2oaDBw9Oui8A+NX+uHDhAtatW4fExERHZynx8fEwGo1O6/TGNvhdMBCR7/nVqQQR+QcGAxFJMBiISILBQEQSDAYikmAwEJEEg4GIJP4PSTTeyetJcLoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Xk9WeAx9Wl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "995b22f9-80cd-4582-8e20-48c129b23d9b"
      },
      "source": [
        "# in the same step convert ouput by using one hot encoding \n",
        "y_train = to_categorical(y_train)\n",
        "y_test  = to_categorical(y_test)\n",
        "y_train[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Otslt-FyA5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function get code\n",
        "def getcode(n):\n",
        "    for x,y in code.items():\n",
        "        if n ==y :\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg2DC9rryDq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np \n",
        "from tensorflow.keras.applications import vgg16 , inception_v3 , resnet50 , mobilenet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk4Qdx3hyHu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "vgg_model = vgg16.VGG16(weights='imagenet')\n",
        "\n",
        "#Load the Inception_V3 model\n",
        "inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
        "\n",
        "#Load the ResNet50 model\n",
        "resnet_model = resnet50.ResNet50(weights='imagenet')\n",
        "\n",
        "#Load the MobileNet model\n",
        "mobilenet_model = mobilenet.MobileNet(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nfp_kPoycol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.applications.imagenet_utils import decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyKX6maRzHR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch = np.expand_dims(x_train[0], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GF91meKzQkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "630d4d44-29c6-4da7-c024-4d7c92adaf7b"
      },
      "source": [
        "print('image batch size', image_batch.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image batch size (1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uSmoNWJ5QMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "308e1f4b-fcbd-490c-9706-088886f150b0"
      },
      "source": [
        "#preprocess for vgg16\n",
        "processed_image_vgg16 = vgg16.preprocess_input(image_batch.copy())\n",
        "\n",
        "#preprocess for resnet50\n",
        "processed_image_resnet50 = resnet50.preprocess_input(image_batch.copy())\n",
        "\n",
        "#preprocess for mobilenet\n",
        "processed_image_mobilenet = mobilenet.preprocess_input(image_batch.copy())\n",
        "\n",
        "# Predict the Image label\n",
        "# vgg16\n",
        "predictions_vgg16 = vgg_model.predict(processed_image_vgg16)\n",
        "label_vgg16 = decode_predictions(predictions_vgg16 , top=3)\n",
        "print ('label_vgg16 = ', label_vgg16)\n",
        "\n",
        "# resnet50\n",
        "predictions_resnet50 = resnet_model.predict(processed_image_resnet50)\n",
        "label_resnet50 = decode_predictions(predictions_resnet50 , top=3 )\n",
        "print ('label_resnet50 = ', label_resnet50)\n",
        "\n",
        "# mobilenet\n",
        "predictions_mobilenet = mobilenet_model.predict(processed_image_mobilenet)\n",
        "label_mobilenet = decode_predictions(predictions_mobilenet , top = 3)\n",
        "print ('label_mobilenet = ', label_mobilenet)\n",
        "\n",
        "print(label_vgg16[0][0][1])\n",
        "print('The heighst prediction is : %s(%.2f%%)' % (label_vgg16[0][0][1] , label_vgg16[0][0][2]*100 ) )\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label_vgg16 =  [[('n03729826', 'matchstick', 0.08734357), ('n01930112', 'nematode', 0.05465962), ('n04286575', 'spotlight', 0.030802974)]]\n",
            "label_resnet50 =  [[('n03729826', 'matchstick', 0.0766837), ('n03196217', 'digital_clock', 0.076420695), ('n04286575', 'spotlight', 0.06996454)]]\n",
            "label_mobilenet =  [[('n01930112', 'nematode', 0.05042505), ('n04286575', 'spotlight', 0.04840996), ('n03729826', 'matchstick', 0.043757763)]]\n",
            "matchstick\n",
            "The heighst prediction is : matchstick(8.73%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTYEr6f49b8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebe8vIu19cEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQu83JPm9cTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46c46a63-491f-4e7b-89fe-7bb08c2b4346"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "features = model.predict(processed_image_vgg16) \n",
        "print(features.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONPpv5K9zt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "c834cf02-689a-4034-ff40-6fd9f5422725"
      },
      "source": [
        "\n",
        "VGG = VGG16(include_top=False , input_shape = (224 ,224,3))\n",
        "for layer in VGG.layers[:10]:  # to freeze all layer, remove the slicing [:10] \n",
        "  layer.trainable = False \n",
        "\n",
        "# Lets print the VGG layers\n",
        "for layer in VGG.layers: \n",
        "  print(layer.name , layer.trainable)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_6 False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool True\n",
            "block4_conv1 True\n",
            "block4_conv2 True\n",
            "block4_conv3 True\n",
            "block4_pool True\n",
            "block5_conv1 True\n",
            "block5_conv2 True\n",
            "block5_conv3 True\n",
            "block5_pool True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kahK7mRR-02O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff3a4aba-4613-4333-a3e4-0b52c2a4187e"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# create the base pre-trained model ( Remove the default classifier from the model architecture )\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "#for i, layer in enumerate(base_model.layers):\n",
        "   #print(i, layer.name)\n",
        "\n",
        "\n",
        "# lets add our own classifier\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "print(x.shape)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(200, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train \n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "# compile the model (should be done after setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "model.fit(...)\n",
        "\n",
        "# Till now, only the top layers ( classifier ) are well trained \n",
        "\n",
        "# Lets start fine-tuning convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(...)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, None, 2048)\n",
            "0 input_7\n",
            "1 conv2d_94\n",
            "2 batch_normalization_94\n",
            "3 activation_94\n",
            "4 conv2d_95\n",
            "5 batch_normalization_95\n",
            "6 activation_95\n",
            "7 conv2d_96\n",
            "8 batch_normalization_96\n",
            "9 activation_96\n",
            "10 max_pooling2d_4\n",
            "11 conv2d_97\n",
            "12 batch_normalization_97\n",
            "13 activation_97\n",
            "14 conv2d_98\n",
            "15 batch_normalization_98\n",
            "16 activation_98\n",
            "17 max_pooling2d_5\n",
            "18 conv2d_102\n",
            "19 batch_normalization_102\n",
            "20 activation_102\n",
            "21 conv2d_100\n",
            "22 conv2d_103\n",
            "23 batch_normalization_100\n",
            "24 batch_normalization_103\n",
            "25 activation_100\n",
            "26 activation_103\n",
            "27 average_pooling2d_9\n",
            "28 conv2d_99\n",
            "29 conv2d_101\n",
            "30 conv2d_104\n",
            "31 conv2d_105\n",
            "32 batch_normalization_99\n",
            "33 batch_normalization_101\n",
            "34 batch_normalization_104\n",
            "35 batch_normalization_105\n",
            "36 activation_99\n",
            "37 activation_101\n",
            "38 activation_104\n",
            "39 activation_105\n",
            "40 mixed0\n",
            "41 conv2d_109\n",
            "42 batch_normalization_109\n",
            "43 activation_109\n",
            "44 conv2d_107\n",
            "45 conv2d_110\n",
            "46 batch_normalization_107\n",
            "47 batch_normalization_110\n",
            "48 activation_107\n",
            "49 activation_110\n",
            "50 average_pooling2d_10\n",
            "51 conv2d_106\n",
            "52 conv2d_108\n",
            "53 conv2d_111\n",
            "54 conv2d_112\n",
            "55 batch_normalization_106\n",
            "56 batch_normalization_108\n",
            "57 batch_normalization_111\n",
            "58 batch_normalization_112\n",
            "59 activation_106\n",
            "60 activation_108\n",
            "61 activation_111\n",
            "62 activation_112\n",
            "63 mixed1\n",
            "64 conv2d_116\n",
            "65 batch_normalization_116\n",
            "66 activation_116\n",
            "67 conv2d_114\n",
            "68 conv2d_117\n",
            "69 batch_normalization_114\n",
            "70 batch_normalization_117\n",
            "71 activation_114\n",
            "72 activation_117\n",
            "73 average_pooling2d_11\n",
            "74 conv2d_113\n",
            "75 conv2d_115\n",
            "76 conv2d_118\n",
            "77 conv2d_119\n",
            "78 batch_normalization_113\n",
            "79 batch_normalization_115\n",
            "80 batch_normalization_118\n",
            "81 batch_normalization_119\n",
            "82 activation_113\n",
            "83 activation_115\n",
            "84 activation_118\n",
            "85 activation_119\n",
            "86 mixed2\n",
            "87 conv2d_121\n",
            "88 batch_normalization_121\n",
            "89 activation_121\n",
            "90 conv2d_122\n",
            "91 batch_normalization_122\n",
            "92 activation_122\n",
            "93 conv2d_120\n",
            "94 conv2d_123\n",
            "95 batch_normalization_120\n",
            "96 batch_normalization_123\n",
            "97 activation_120\n",
            "98 activation_123\n",
            "99 max_pooling2d_6\n",
            "100 mixed3\n",
            "101 conv2d_128\n",
            "102 batch_normalization_128\n",
            "103 activation_128\n",
            "104 conv2d_129\n",
            "105 batch_normalization_129\n",
            "106 activation_129\n",
            "107 conv2d_125\n",
            "108 conv2d_130\n",
            "109 batch_normalization_125\n",
            "110 batch_normalization_130\n",
            "111 activation_125\n",
            "112 activation_130\n",
            "113 conv2d_126\n",
            "114 conv2d_131\n",
            "115 batch_normalization_126\n",
            "116 batch_normalization_131\n",
            "117 activation_126\n",
            "118 activation_131\n",
            "119 average_pooling2d_12\n",
            "120 conv2d_124\n",
            "121 conv2d_127\n",
            "122 conv2d_132\n",
            "123 conv2d_133\n",
            "124 batch_normalization_124\n",
            "125 batch_normalization_127\n",
            "126 batch_normalization_132\n",
            "127 batch_normalization_133\n",
            "128 activation_124\n",
            "129 activation_127\n",
            "130 activation_132\n",
            "131 activation_133\n",
            "132 mixed4\n",
            "133 conv2d_138\n",
            "134 batch_normalization_138\n",
            "135 activation_138\n",
            "136 conv2d_139\n",
            "137 batch_normalization_139\n",
            "138 activation_139\n",
            "139 conv2d_135\n",
            "140 conv2d_140\n",
            "141 batch_normalization_135\n",
            "142 batch_normalization_140\n",
            "143 activation_135\n",
            "144 activation_140\n",
            "145 conv2d_136\n",
            "146 conv2d_141\n",
            "147 batch_normalization_136\n",
            "148 batch_normalization_141\n",
            "149 activation_136\n",
            "150 activation_141\n",
            "151 average_pooling2d_13\n",
            "152 conv2d_134\n",
            "153 conv2d_137\n",
            "154 conv2d_142\n",
            "155 conv2d_143\n",
            "156 batch_normalization_134\n",
            "157 batch_normalization_137\n",
            "158 batch_normalization_142\n",
            "159 batch_normalization_143\n",
            "160 activation_134\n",
            "161 activation_137\n",
            "162 activation_142\n",
            "163 activation_143\n",
            "164 mixed5\n",
            "165 conv2d_148\n",
            "166 batch_normalization_148\n",
            "167 activation_148\n",
            "168 conv2d_149\n",
            "169 batch_normalization_149\n",
            "170 activation_149\n",
            "171 conv2d_145\n",
            "172 conv2d_150\n",
            "173 batch_normalization_145\n",
            "174 batch_normalization_150\n",
            "175 activation_145\n",
            "176 activation_150\n",
            "177 conv2d_146\n",
            "178 conv2d_151\n",
            "179 batch_normalization_146\n",
            "180 batch_normalization_151\n",
            "181 activation_146\n",
            "182 activation_151\n",
            "183 average_pooling2d_14\n",
            "184 conv2d_144\n",
            "185 conv2d_147\n",
            "186 conv2d_152\n",
            "187 conv2d_153\n",
            "188 batch_normalization_144\n",
            "189 batch_normalization_147\n",
            "190 batch_normalization_152\n",
            "191 batch_normalization_153\n",
            "192 activation_144\n",
            "193 activation_147\n",
            "194 activation_152\n",
            "195 activation_153\n",
            "196 mixed6\n",
            "197 conv2d_158\n",
            "198 batch_normalization_158\n",
            "199 activation_158\n",
            "200 conv2d_159\n",
            "201 batch_normalization_159\n",
            "202 activation_159\n",
            "203 conv2d_155\n",
            "204 conv2d_160\n",
            "205 batch_normalization_155\n",
            "206 batch_normalization_160\n",
            "207 activation_155\n",
            "208 activation_160\n",
            "209 conv2d_156\n",
            "210 conv2d_161\n",
            "211 batch_normalization_156\n",
            "212 batch_normalization_161\n",
            "213 activation_156\n",
            "214 activation_161\n",
            "215 average_pooling2d_15\n",
            "216 conv2d_154\n",
            "217 conv2d_157\n",
            "218 conv2d_162\n",
            "219 conv2d_163\n",
            "220 batch_normalization_154\n",
            "221 batch_normalization_157\n",
            "222 batch_normalization_162\n",
            "223 batch_normalization_163\n",
            "224 activation_154\n",
            "225 activation_157\n",
            "226 activation_162\n",
            "227 activation_163\n",
            "228 mixed7\n",
            "229 conv2d_166\n",
            "230 batch_normalization_166\n",
            "231 activation_166\n",
            "232 conv2d_167\n",
            "233 batch_normalization_167\n",
            "234 activation_167\n",
            "235 conv2d_164\n",
            "236 conv2d_168\n",
            "237 batch_normalization_164\n",
            "238 batch_normalization_168\n",
            "239 activation_164\n",
            "240 activation_168\n",
            "241 conv2d_165\n",
            "242 conv2d_169\n",
            "243 batch_normalization_165\n",
            "244 batch_normalization_169\n",
            "245 activation_165\n",
            "246 activation_169\n",
            "247 max_pooling2d_7\n",
            "248 mixed8\n",
            "249 conv2d_174\n",
            "250 batch_normalization_174\n",
            "251 activation_174\n",
            "252 conv2d_171\n",
            "253 conv2d_175\n",
            "254 batch_normalization_171\n",
            "255 batch_normalization_175\n",
            "256 activation_171\n",
            "257 activation_175\n",
            "258 conv2d_172\n",
            "259 conv2d_173\n",
            "260 conv2d_176\n",
            "261 conv2d_177\n",
            "262 average_pooling2d_16\n",
            "263 conv2d_170\n",
            "264 batch_normalization_172\n",
            "265 batch_normalization_173\n",
            "266 batch_normalization_176\n",
            "267 batch_normalization_177\n",
            "268 conv2d_178\n",
            "269 batch_normalization_170\n",
            "270 activation_172\n",
            "271 activation_173\n",
            "272 activation_176\n",
            "273 activation_177\n",
            "274 batch_normalization_178\n",
            "275 activation_170\n",
            "276 mixed9_0\n",
            "277 concatenate_2\n",
            "278 activation_178\n",
            "279 mixed9\n",
            "280 conv2d_183\n",
            "281 batch_normalization_183\n",
            "282 activation_183\n",
            "283 conv2d_180\n",
            "284 conv2d_184\n",
            "285 batch_normalization_180\n",
            "286 batch_normalization_184\n",
            "287 activation_180\n",
            "288 activation_184\n",
            "289 conv2d_181\n",
            "290 conv2d_182\n",
            "291 conv2d_185\n",
            "292 conv2d_186\n",
            "293 average_pooling2d_17\n",
            "294 conv2d_179\n",
            "295 batch_normalization_181\n",
            "296 batch_normalization_182\n",
            "297 batch_normalization_185\n",
            "298 batch_normalization_186\n",
            "299 conv2d_187\n",
            "300 batch_normalization_179\n",
            "301 activation_181\n",
            "302 activation_182\n",
            "303 activation_185\n",
            "304 activation_186\n",
            "305 batch_normalization_187\n",
            "306 activation_179\n",
            "307 mixed9_1\n",
            "308 concatenate_3\n",
            "309 activation_187\n",
            "310 mixed10\n",
            "311 global_average_pooling2d_1\n",
            "312 dense\n",
            "313 dense_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d6746ad94862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# train the model on the new data for a few epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Till now, only the top layers ( classifier ) are well trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 963\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    964\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'ellipsis'>, <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYhf64wu-174",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "a910d44c-3326-4aee-f526-c521a9af3efd"
      },
      "source": [
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(Conv2D(64, kernel_size = 3 , input_shape =(224,224,3)))\n",
        "model.add(VGG16().layers[2])  # adding 3rd layer of pretrained model\n",
        "model.summary()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        multiple                  36928     \n",
            "=================================================================\n",
            "Total params: 38,720\n",
            "Trainable params: 38,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdVjbrarCw38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ebc4313-47df-403b-86e3-f33bfbeb98e5"
      },
      "source": [
        "x_testing =np.expand_dims(x_test,axis=1)\n",
        "\n",
        "print(x_testing.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(341, 1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fiLn11_96t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "prediction =model.predict(x_testing[50])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wxJeQieFgDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfLXKTNdGnJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d3d5a186-8113-404d-f182-bf9c28e26775"
      },
      "source": [
        "results=confusion_matrix(y_test[100],prediction)\n",
        " "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-fb4d7c21b96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [62, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxKvtZuTHpFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "ef6ac5dc-cfd1-47ff-f426-f91f7422b2a2"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "sns.heatmap(results,center=True)\n",
        "plt.show() \n",
        "print ('Accuracy Score :',accuracy_score(y_test, y_pred.round(), normalize=False))\n",
        "print ('Report : ')\n",
        "print (classification_report(y_test, y_pred))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-a52e0106830c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion Matrix :'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    }
  ]
}